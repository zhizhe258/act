#!/usr/bin/env python3
"""
Convert Parquet to HDF5 Format with Real Images
===============================================

ä½¿ç”¨ffmpegä»è§†é¢‘æ–‡ä»¶ä¸­æå–çœŸå®å›¾åƒæ•°æ®ï¼Œå°†parquetæ ¼å¼è½¬æ¢ä¸ºHDF5æ ¼å¼ã€‚
"""

import pandas as pd
import numpy as np
import h5py
import os
import cv2
import subprocess
from tqdm import tqdm
import argparse
import tempfile
import shutil

def extract_frames_from_video(video_path, output_dir, frame_indices):
    """
    ä½¿ç”¨ffmpegä»è§†é¢‘ä¸­æå–æŒ‡å®šå¸§
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        frame_indices: è¦æå–çš„å¸§ç´¢å¼•åˆ—è¡¨
    
    Returns:
        æå–çš„å¸§åˆ—è¡¨
    """
    frames = []
    
    try:
        # ä½¿ç”¨ffmpegæå–å¸§
        for i, frame_idx in enumerate(frame_indices):
            # æ„å»ºffmpegå‘½ä»¤
            output_frame = os.path.join(output_dir, f'frame_{i:06d}.jpg')
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vf', f'select=eq(n\\,{frame_idx})',
                '-vframes', '1',
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_frame
            ]
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and os.path.exists(output_frame):
                # è¯»å–æå–çš„å¸§
                frame = cv2.imread(output_frame)
                if frame is not None:
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGR to RGB
                    frames.append(frame)
                else:
                    # å¦‚æœè¯»å–å¤±è´¥ï¼Œåˆ›å»ºé»‘è‰²å¸§
                    frames.append(np.zeros((480, 640, 3), dtype=np.uint8))
            else:
                # å¦‚æœæå–å¤±è´¥ï¼Œåˆ›å»ºé»‘è‰²å¸§
                frames.append(np.zeros((480, 640, 3), dtype=np.uint8))
                
    except Exception as e:
        print(f"Warning: Failed to extract frames from {video_path}: {e}")
        # åˆ›å»ºé»‘è‰²å¸§ä½œä¸ºfallback
        frames = [np.zeros((480, 640, 3), dtype=np.uint8) for _ in frame_indices]
    
    return frames

def convert_parquet_to_hdf5_with_images(parquet_dir, output_dir, num_episodes=None):
    """
    å°†parquetæ ¼å¼çš„æ•°æ®è½¬æ¢ä¸ºHDF5æ ¼å¼ï¼ŒåŒ…å«çœŸå®å›¾åƒæ•°æ®
    
    Args:
        parquet_dir: parquetæ•°æ®ç›®å½•
        output_dir: è¾“å‡ºHDF5æ–‡ä»¶ç›®å½•
        num_episodes: è¦è½¬æ¢çš„episodeæ•°é‡ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
    """
    print(f"ğŸ”„ å¼€å§‹è½¬æ¢parquetåˆ°HDF5æ ¼å¼ï¼ˆåŒ…å«çœŸå®å›¾åƒï¼‰...")
    print(f"   è¾“å…¥ç›®å½•: {parquet_dir}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    
    # è¯»å–parquetæ–‡ä»¶
    parquet_path = os.path.join(parquet_dir, 'data', 'train-00000-of-00001.parquet')
    if not os.path.exists(parquet_path):
        raise FileNotFoundError(f"Parquetæ–‡ä»¶ä¸å­˜åœ¨: {parquet_path}")
    
    df = pd.read_parquet(parquet_path)
    print(f"ğŸ“Š æ€»æ•°æ®ç‚¹: {len(df)}")
    print(f"ğŸ“Š å¯ç”¨episodes: {df['episode_index'].max() + 1}")
    
    # é™åˆ¶episodeæ•°é‡
    if num_episodes is not None:
        df = df[df['episode_index'] < num_episodes]
        print(f"ğŸ“Š ä½¿ç”¨episodes: 0-{num_episodes-1}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå¸§æå–
    temp_dir = tempfile.mkdtemp()
    
    try:
        # æŒ‰episodeåˆ†ç»„å¤„ç†
        episode_groups = df.groupby('episode_index')
        total_episodes = len(episode_groups)
        
        print(f"ğŸ¯ å¼€å§‹è½¬æ¢ {total_episodes} ä¸ªepisodes...")
        
        for episode_idx, episode_data in tqdm(episode_groups, desc="è½¬æ¢episodes"):
            # æŒ‰frame_indexæ’åº
            episode_data = episode_data.sort_values('frame_index')
            
            # åˆ›å»ºHDF5æ–‡ä»¶
            hdf5_path = os.path.join(output_dir, f'episode_{episode_idx}.hdf5')
            
            with h5py.File(hdf5_path, 'w') as f:
                # è®¾ç½®å±æ€§
                f.attrs['sim'] = True
                
                # æå–observations
                qpos_list = []
                qvel_list = []
                
                for _, row in episode_data.iterrows():
                    # æå–stateæ•°æ® (14D)
                    state = np.frombuffer(row['observation.state'], dtype=np.float32)
                    qpos_list.append(state)
                    
                    # å¯¹äºqvelï¼Œæˆ‘ä»¬æš‚æ—¶ç”¨é›¶å¡«å……ï¼Œå› ä¸ºparquetä¸­æ²¡æœ‰velocityæ•°æ®
                    qvel = np.zeros(14, dtype=np.float32)
                    qvel_list.append(qvel)
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                qpos = np.array(qpos_list)  # (episode_len, 14)
                qvel = np.array(qvel_list)  # (episode_len, 14)
                
                # æå–actionæ•°æ®
                action_list = []
                for _, row in episode_data.iterrows():
                    action = np.frombuffer(row['action'], dtype=np.float32)
                    action_list.append(action)
                
                action = np.array(action_list)  # (episode_len, 14)
                
                # å†™å…¥HDF5æ–‡ä»¶
                f.create_dataset('/observations/qpos', data=qpos)
                f.create_dataset('/observations/qvel', data=qvel)
                f.create_dataset('/action', data=action)
                
                # æå–çœŸå®å›¾åƒæ•°æ®
                episode_len = len(qpos)
                camera_names = ['overhead_cam', 'worms_eye_cam', 'wrist_cam_left', 'wrist_cam_right']
                
                for cam_name in camera_names:
                    # è·å–è¯¥ç›¸æœºçš„è§†é¢‘è·¯å¾„
                    first_row = episode_data.iloc[0]
                    img_info = first_row[f'observation.images.{cam_name}']
                    
                    if isinstance(img_info, dict) and 'path' in img_info:
                        video_path = img_info['path']
                        base_dir = parquet_dir
                        full_video_path = os.path.join(base_dir, video_path)
                        
                        if os.path.exists(full_video_path):
                            # æå–æ‰€æœ‰å¸§
                            frame_indices = list(range(episode_len))
                            frames = extract_frames_from_video(full_video_path, temp_dir, frame_indices)
                            
                            if frames:
                                # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è°ƒæ•´å°ºå¯¸
                                frames_array = np.array(frames)  # (episode_len, H, W, 3)
                                # è°ƒæ•´å°ºå¯¸åˆ°æ ‡å‡†å¤§å°
                                resized_frames = []
                                for frame in frames_array:
                                    resized = cv2.resize(frame, (640, 480))
                                    resized_frames.append(resized)
                                
                                frames_array = np.array(resized_frames)  # (episode_len, 480, 640, 3)
                                f.create_dataset(f'/observations/images/{cam_name}', data=frames_array)
                                print(f"   Episode {episode_idx} {cam_name}: æå–äº† {len(frames)} å¸§")
                            else:
                                # å¦‚æœæå–å¤±è´¥ï¼Œåˆ›å»ºå‡æ•°æ®
                                fake_images = np.random.randint(0, 256, (episode_len, 480, 640, 3), dtype=np.uint8) * 0.1
                                f.create_dataset(f'/observations/images/{cam_name}', data=fake_images)
                                print(f"   Episode {episode_idx} {cam_name}: ä½¿ç”¨å‡æ•°æ®")
                        else:
                            # å¦‚æœè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå‡æ•°æ®
                            fake_images = np.random.randint(0, 256, (episode_len, 480, 640, 3), dtype=np.uint8) * 0.1
                            f.create_dataset(f'/observations/images/{cam_name}', data=fake_images)
                            print(f"   Episode {episode_idx} {cam_name}: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨å‡æ•°æ®")
                    else:
                        # å¦‚æœå›¾åƒä¿¡æ¯æ ¼å¼ä¸å¯¹ï¼Œåˆ›å»ºå‡æ•°æ®
                        fake_images = np.random.randint(0, 256, (episode_len, 480, 640, 3), dtype=np.uint8) * 0.1
                        f.create_dataset(f'/observations/images/{cam_name}', data=fake_images)
                        print(f"   Episode {episode_idx} {cam_name}: æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨å‡æ•°æ®")
                
                print(f"   Episode {episode_idx}: {len(qpos)} æ­¥, qpos shape: {qpos.shape}, action shape: {action.shape}")
        
        print(f"âœ… è½¬æ¢å®Œæˆï¼")
        print(f"   è¾“å‡ºç›®å½•: {output_dir}")
        print(f"   è½¬æ¢çš„episodes: {total_episodes}")
        
        # éªŒè¯è½¬æ¢ç»“æœ
        print(f"\nğŸ” éªŒè¯è½¬æ¢ç»“æœ...")
        test_file = os.path.join(output_dir, 'episode_0.hdf5')
        if os.path.exists(test_file):
            with h5py.File(test_file, 'r') as f:
                print(f"   Episode 0 éªŒè¯:")
                print(f"     qpos shape: {f['/observations/qpos'].shape}")
                print(f"     qvel shape: {f['/observations/qvel'].shape}")
                print(f"     action shape: {f['/action'].shape}")
                print(f"     sim attribute: {f.attrs.get('sim', 'Not found')}")
                
                # æ£€æŸ¥å›¾åƒæ•°æ®
                for cam_name in ['overhead_cam', 'worms_eye_cam', 'wrist_cam_left', 'wrist_cam_right']:
                    if f'/observations/images/{cam_name}' in f:
                        img_shape = f[f'/observations/images/{cam_name}'].shape
                        print(f"     {cam_name} images shape: {img_shape}")
        
        return output_dir
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(temp_dir, ignore_errors=True)

def main():
    parser = argparse.ArgumentParser(description='å°†parquetæ ¼å¼è½¬æ¢ä¸ºHDF5æ ¼å¼ï¼ˆåŒ…å«çœŸå®å›¾åƒï¼‰')
    parser.add_argument('--parquet_dir', type=str, 
                       default='/home/zzt/actnew/data/gv_sim_slot_insertion_2arms',
                       help='parquetæ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str,
                       default='/home/zzt/actnew/data/converted_bimanual_aloha_slot_insertion_with_vel',
                       help='è¾“å‡ºHDF5æ–‡ä»¶ç›®å½•')
    parser.add_argument('--num_episodes', type=int, default=5,
                       help='è¦è½¬æ¢çš„episodeæ•°é‡ï¼ˆå»ºè®®å…ˆç”¨å°‘é‡æµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    try:
        output_dir = convert_parquet_to_hdf5_with_images(
            args.parquet_dir, 
            args.output_dir, 
            args.num_episodes
        )
        print(f"\nğŸ‰ è½¬æ¢æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨åŸæœ‰çš„è®­ç»ƒä»£ç äº†ã€‚")
        print(f"   è®­ç»ƒå‘½ä»¤ç¤ºä¾‹:")
        print(f"   python3 imitate_episodes_bimanual.py \\")
        print(f"       --task_name converted_bimanual_aloha_slot_insertion_with_vel \\")
        print(f"       --policy_class ACT \\")
        print(f"       --batch_size 8 \\")
        print(f"       --num_epochs 2000")
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main() 